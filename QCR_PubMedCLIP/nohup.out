2022-08-01 16:46:38,632 INFO     >>>The net is:
2022-08-01 16:46:38,632 INFO     BAN_Model(
  (graph_model): GraphModel(
    (gcn1): GCN(
      (apply_mod): NodeApplyModule(
        (linear): Linear(in_features=300, out_features=512, bias=True)
      )
    )
    (gcn2): GCN(
      (apply_mod): NodeApplyModule(
        (linear): Linear(in_features=512, out_features=1024, bias=True)
      )
    )
  )
  (w_emb): WordEmbedding(
    (emb): Embedding(293, 300, padding_idx=292)
    (emb_): Embedding(293, 300, padding_idx=292)
    (dropout): Dropout(p=0.0, inplace=False)
  )
  (q_emb): QuestionEmbedding(
    (rnn): GRU(600, 1024, batch_first=True)
  )
  (k_emb): WordEmbedding(
    (emb): Embedding(293, 300, padding_idx=292)
    (emb_): Embedding(293, 300, padding_idx=292)
    (dropout): Dropout(p=0.0, inplace=False)
  )
  (keywords_emb): QuestionEmbedding(
    (rnn): GRU(600, 1024, batch_first=True)
  )
  (close_att): BiAttention(
    (logits): BCNet(
      (v_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=576, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (q_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (dropout): Dropout(p=0.5, inplace=False)
      (p_net): AvgPool1d(kernel_size=(3,), stride=(3,), padding=(0,))
    )
  )
  (close_resnet): BiResNet(
    (b_net): ModuleList(
      (0): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (1): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (2): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (3): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (4): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (5): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (6): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (7): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (8): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (9): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (q_prj): ModuleList(
      (0): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (1): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (2): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (3): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (4): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (5): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (6): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (7): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (8): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (9): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
    )
    (c_prj): ModuleList()
  )
  (close_classifier): SimpleClassifier(
    (main): Sequential(
      (0): Linear(in_features=1024, out_features=2048, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=2048, out_features=35, bias=True)
    )
  )
  (open_att): BiAttention(
    (logits): BCNet(
      (v_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=576, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (q_net): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=3072, bias=True)
          (2): ReLU()
        )
      )
      (dropout): Dropout(p=0.5, inplace=False)
      (p_net): AvgPool1d(kernel_size=(3,), stride=(3,), padding=(0,))
    )
  )
  (open_resnet): BiResNet(
    (b_net): ModuleList(
      (0): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (1): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (2): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (3): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (4): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (5): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (6): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (7): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (8): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
      (9): BCNet(
        (v_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=576, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (q_net): FCNet(
          (main): Sequential(
            (0): Dropout(p=0.2, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): ReLU()
          )
        )
        (dropout): Dropout(p=0.5, inplace=False)
      )
    )
    (q_prj): ModuleList(
      (0): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (1): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (2): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (3): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (4): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (5): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (6): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (7): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (8): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
      (9): FCNet(
        (main): Sequential(
          (0): Dropout(p=0.2, inplace=False)
          (1): Linear(in_features=1024, out_features=1024, bias=True)
        )
      )
    )
    (c_prj): ModuleList()
  )
  (open_classifier): SimpleClassifier(
    (main): Sequential(
      (0): Linear(in_features=1024, out_features=2048, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=2048, out_features=219, bias=True)
    )
  )
  (bbn_classifier): SimpleClassifier(
    (main): Sequential(
      (0): Linear(in_features=2048, out_features=3072, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=3072, out_features=254, bias=True)
    )
  )
  (typeatt): typeAttention(
    (w_emb): WordEmbedding(
      (emb): Embedding(293, 300, padding_idx=292)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (q_emb): QuestionEmbedding(
      (rnn): GRU(300, 1024, batch_first=True)
    )
    (q_final): QuestionAttention(
      (tanh_gate): Linear(in_features=1324, out_features=1024, bias=True)
      (sigmoid_gate): Linear(in_features=1324, out_features=1024, bias=True)
      (attn): Linear(in_features=1024, out_features=1, bias=True)
    )
    (f_fc1): Linear(in_features=1024, out_features=2048, bias=True)
    (f_fc2): Linear(in_features=2048, out_features=1024, bias=True)
    (f_fc3): Linear(in_features=1024, out_features=1024, bias=True)
  )
  (ae): Auto_Encoder_Model(
    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (conv3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (tran_conv1): ConvTranspose2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (tran_conv2): ConvTranspose2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
    (conv5): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (convert): Linear(in_features=16384, out_features=64, bias=True)
  (clip): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
loading dictionary from ./data/data_slake/dictionary.pkl
loading DAE image data from file: ./data/data_slake/images128x128.pkl
loading CLIP image data from file: ./data/data_slake/images250x250.pkl
loading DAE image data from file: ./data/data_slake/images128x128.pkl
loading CLIP image data from file: ./data/data_slake/images250x250.pkl
load initial weights DAE from: ./data/data_slake/pretrained_ae.pth
loading dictionary from ./data/data_slake/dictionary.pkl
Loading embedding tfidf and weights from file
Load embedding tfidf and weights from file successfully
2022-08-01 16:48:10,413 INFO     -------[Epoch]:0-------
2022-08-01 16:48:10,413 INFO     [Train] Loss:0.120287 , Train_Acc:27.485262%
2022-08-01 16:48:10,413 INFO     [Train] Loss_Open:0.003119 , Loss_Close:0.014289%
2022-08-01 16:48:13,846 INFO     [Validate] Val_Acc:38.360039%  |  Open_ACC:29.566563%   |  Close_ACC:52.048195%
2022-08-01 16:48:30,513 INFO     [Result] The best acc is 38.360039% at epoch 0
1061 646.0 415.0
2022-08-01 16:51:14,949 INFO     -------[Epoch]:1-------
2022-08-01 16:51:14,949 INFO     [Train] Loss:0.063274 , Train_Acc:46.960766%
2022-08-01 16:51:14,949 INFO     [Train] Loss_Open:0.001629 , Loss_Close:0.007534%
2022-08-01 16:51:18,072 INFO     [Validate] Val_Acc:51.649387%  |  Open_ACC:48.682171%   |  Close_ACC:56.250004%
2022-08-01 16:51:34,776 INFO     [Result] The best acc is 51.649387% at epoch 1
1061 645.0 416.0
2022-08-01 16:53:07,626 INFO     -------[Epoch]:2-------
2022-08-01 16:53:07,626 INFO     [Train] Loss:0.051828 , Train_Acc:58.121571%
2022-08-01 16:53:07,626 INFO     [Train] Loss_Open:0.001223 , Loss_Close:0.006341%
2022-08-01 16:53:10,818 INFO     [Validate] Val_Acc:62.582470%  |  Open_ACC:60.310078%   |  Close_ACC:66.105774%
2022-08-01 16:53:27,787 INFO     [Result] The best acc is 62.582470% at epoch 2
1061 645.0 416.0
2022-08-01 16:54:53,870 INFO     -------[Epoch]:3-------
2022-08-01 16:54:53,871 INFO     [Train] Loss:0.044161 , Train_Acc:66.375282%
2022-08-01 16:54:53,871 INFO     [Train] Loss_Open:0.001005 , Loss_Close:0.005459%
2022-08-01 16:54:56,953 INFO     [Validate] Val_Acc:64.655983%  |  Open_ACC:63.003094%   |  Close_ACC:67.228920%
2022-08-01 16:55:13,782 INFO     [Result] The best acc is 64.655983% at epoch 3
1061 646.0 415.0
2022-08-01 16:56:34,767 INFO     -------[Epoch]:4-------
2022-08-01 16:56:34,767 INFO     [Train] Loss:0.037934 , Train_Acc:70.075218%
2022-08-01 16:56:34,767 INFO     [Train] Loss_Open:0.000851 , Loss_Close:0.004709%
2022-08-01 16:56:37,868 INFO     [Validate] Val_Acc:64.750237%  |  Open_ACC:64.496124%   |  Close_ACC:65.144234%
2022-08-01 16:56:57,537 INFO     [Result] The best acc is 64.750237% at epoch 4
1061 645.0 416.0
2022-08-01 16:58:19,007 INFO     -------[Epoch]:5-------
2022-08-01 16:58:19,007 INFO     [Train] Loss:0.033417 , Train_Acc:73.836143%
2022-08-01 16:58:19,007 INFO     [Train] Loss_Open:0.000771 , Loss_Close:0.004116%
2022-08-01 16:58:22,005 INFO     [Validate] Val_Acc:67.389252%  |  Open_ACC:66.821709%   |  Close_ACC:68.269234%
2022-08-01 16:58:41,890 INFO     [Result] The best acc is 67.389252% at epoch 5
1061 645.0 416.0
2022-08-01 17:00:27,700 INFO     -------[Epoch]:6-------
2022-08-01 17:00:27,700 INFO     [Train] Loss:0.030449 , Train_Acc:76.174019%
2022-08-01 17:00:27,700 INFO     [Train] Loss_Open:0.000708 , Loss_Close:0.003742%
2022-08-01 17:00:31,196 INFO     [Validate] Val_Acc:69.274269%  |  Open_ACC:69.612404%   |  Close_ACC:68.750000%
2022-08-01 17:00:33,335 INFO     [Result] The best acc is 69.274269% at epoch 6
1061 645.0 416.0
2022-08-01 17:01:54,396 INFO     -------[Epoch]:7-------
2022-08-01 17:01:54,396 INFO     [Train] Loss:0.027967 , Train_Acc:77.576744%
2022-08-01 17:01:54,396 INFO     [Train] Loss_Open:0.000642 , Loss_Close:0.003450%
2022-08-01 17:01:57,554 INFO     [Validate] Val_Acc:68.614517%  |  Open_ACC:68.217056%   |  Close_ACC:69.230774%
2022-08-01 17:01:57,554 INFO     [Result] The best acc is 69.274269% at epoch 6
1061 645.0 416.0
2022-08-01 17:03:37,134 INFO     -------[Epoch]:8-------
2022-08-01 17:03:37,134 INFO     [Train] Loss:0.023238 , Train_Acc:80.097580%
2022-08-01 17:03:37,134 INFO     [Train] Loss_Open:0.000598 , Loss_Close:0.002767%
2022-08-01 17:03:40,134 INFO     [Validate] Val_Acc:71.065033%  |  Open_ACC:71.317833%   |  Close_ACC:70.673080%
2022-08-01 17:03:42,135 INFO     [Result] The best acc is 71.065033% at epoch 8
1061 645.0 416.0
2022-08-01 17:05:03,114 INFO     -------[Epoch]:9-------
2022-08-01 17:05:03,114 INFO     [Train] Loss:0.021496 , Train_Acc:81.236023%
2022-08-01 17:05:03,114 INFO     [Train] Loss_Open:0.000543 , Loss_Close:0.002575%
2022-08-01 17:05:06,068 INFO     [Validate] Val_Acc:71.630539%  |  Open_ACC:71.317833%   |  Close_ACC:72.115387%
2022-08-01 17:05:23,184 INFO     [Result] The best acc is 71.630539% at epoch 9
1061 645.0 416.0
2022-08-01 17:06:44,783 INFO     -------[Epoch]:10-------
2022-08-01 17:06:44,783 INFO     [Train] Loss:0.019683 , Train_Acc:82.964020%
2022-08-01 17:06:44,783 INFO     [Train] Loss_Open:0.000523 , Loss_Close:0.002319%
2022-08-01 17:06:48,000 INFO     [Validate] Val_Acc:72.478790%  |  Open_ACC:71.517029%   |  Close_ACC:73.975906%
2022-08-01 17:07:07,478 INFO     [Result] The best acc is 72.478790% at epoch 10
1061 646.0 415.0
2022-08-01 17:10:11,018 INFO     -------[Epoch]:11-------
2022-08-01 17:10:11,018 INFO     [Train] Loss:0.017792 , Train_Acc:83.919495%
2022-08-01 17:10:11,018 INFO     [Train] Loss_Open:0.000494 , Loss_Close:0.002062%
2022-08-01 17:10:14,075 INFO     [Validate] Val_Acc:71.065033%  |  Open_ACC:71.472870%   |  Close_ACC:70.432693%
2022-08-01 17:10:14,076 INFO     [Result] The best acc is 72.478790% at epoch 10
1061 645.0 416.0
2022-08-01 17:12:11,855 INFO     -------[Epoch]:12-------
2022-08-01 17:12:11,856 INFO     [Train] Loss:0.013817 , Train_Acc:85.688148%
2022-08-01 17:12:11,856 INFO     [Train] Loss_Open:0.000466 , Loss_Close:0.001476%
2022-08-01 17:12:15,078 INFO     [Validate] Val_Acc:72.007538%  |  Open_ACC:72.403099%   |  Close_ACC:71.394234%
2022-08-01 17:12:15,078 INFO     [Result] The best acc is 72.478790% at epoch 10
1061 645.0 416.0
2022-08-01 17:14:40,852 INFO     -------[Epoch]:13-------
2022-08-01 17:14:40,853 INFO     [Train] Loss:0.013755 , Train_Acc:86.094734%
2022-08-01 17:14:40,853 INFO     [Train] Loss_Open:0.000436 , Loss_Close:0.001512%
2022-08-01 17:14:43,819 INFO     [Validate] Val_Acc:72.855797%  |  Open_ACC:71.362228%   |  Close_ACC:75.180725%
2022-08-01 17:14:46,000 INFO     [Result] The best acc is 72.855797% at epoch 13
1061 646.0 415.0
2022-08-01 17:17:12,529 INFO     -------[Epoch]:14-------
2022-08-01 17:17:12,529 INFO     [Train] Loss:0.013109 , Train_Acc:87.111206%
2022-08-01 17:17:12,529 INFO     [Train] Loss_Open:0.000426 , Loss_Close:0.001425%
2022-08-01 17:17:15,711 INFO     [Validate] Val_Acc:73.704056%  |  Open_ACC:72.868217%   |  Close_ACC:75.000000%
2022-08-01 17:17:17,807 INFO     [Result] The best acc is 73.704056% at epoch 14
1061 645.0 416.0
2022-08-01 17:18:55,160 INFO     -------[Epoch]:15-------
2022-08-01 17:18:55,160 INFO     [Train] Loss:0.010868 , Train_Acc:88.249649%
2022-08-01 17:18:55,160 INFO     [Train] Loss_Open:0.000384 , Loss_Close:0.001134%
2022-08-01 17:19:02,147 INFO     [Validate] Val_Acc:71.913292%  |  Open_ACC:71.472870%   |  Close_ACC:72.596153%
2022-08-01 17:19:02,147 INFO     [Result] The best acc is 73.704056% at epoch 14
1061 645.0 416.0
2022-08-01 17:20:23,164 INFO     -------[Epoch]:16-------
2022-08-01 17:20:23,164 INFO     [Train] Loss:0.011406 , Train_Acc:88.676559%
2022-08-01 17:20:23,164 INFO     [Train] Loss_Open:0.000366 , Loss_Close:0.001246%
2022-08-01 17:20:28,371 INFO     [Validate] Val_Acc:73.232796%  |  Open_ACC:72.910217%   |  Close_ACC:73.734940%
2022-08-01 17:20:28,371 INFO     [Result] The best acc is 73.704056% at epoch 14
1061 646.0 415.0
2022-08-01 17:21:50,046 INFO     -------[Epoch]:17-------
2022-08-01 17:21:50,046 INFO     [Train] Loss:0.009560 , Train_Acc:90.018295%
2022-08-01 17:21:50,046 INFO     [Train] Loss_Open:0.000336 , Loss_Close:0.001001%
2022-08-01 17:21:53,915 INFO     [Validate] Val_Acc:73.609802%  |  Open_ACC:73.953491%   |  Close_ACC:73.076927%
2022-08-01 17:21:53,915 INFO     [Result] The best acc is 73.704056% at epoch 14
1061 645.0 416.0
2022-08-01 17:24:00,596 INFO     -------[Epoch]:18-------
2022-08-01 17:24:00,596 INFO     [Train] Loss:0.007944 , Train_Acc:90.750153%
2022-08-01 17:24:00,596 INFO     [Train] Loss_Open:0.000327 , Loss_Close:0.000757%
2022-08-01 17:24:03,847 INFO     [Validate] Val_Acc:72.478790%  |  Open_ACC:73.178291%   |  Close_ACC:71.394234%
2022-08-01 17:24:03,847 INFO     [Result] The best acc is 73.704056% at epoch 14
1061 645.0 416.0
2022-08-01 17:25:31,361 INFO     -------[Epoch]:19-------
2022-08-01 17:25:31,361 INFO     [Train] Loss:0.006852 , Train_Acc:91.258385%
2022-08-01 17:25:31,361 INFO     [Train] Loss_Open:0.000306 , Loss_Close:0.000617%
2022-08-01 17:25:34,412 INFO     [Validate] Val_Acc:74.646561%  |  Open_ACC:74.922600%   |  Close_ACC:74.216866%
2022-08-01 17:25:36,421 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 17:27:02,162 INFO     -------[Epoch]:20-------
2022-08-01 17:27:02,162 INFO     [Train] Loss:0.006090 , Train_Acc:92.356171%
2022-08-01 17:27:02,162 INFO     [Train] Loss_Open:0.000272 , Loss_Close:0.000549%
2022-08-01 17:27:05,228 INFO     [Validate] Val_Acc:71.819038%  |  Open_ACC:73.333336%   |  Close_ACC:69.471153%
2022-08-01 17:27:05,228 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 17:28:25,903 INFO     -------[Epoch]:21-------
2022-08-01 17:28:25,903 INFO     [Train] Loss:0.007405 , Train_Acc:92.783089%
2022-08-01 17:28:25,903 INFO     [Train] Loss_Open:0.000258 , Loss_Close:0.000778%
2022-08-01 17:28:29,004 INFO     [Validate] Val_Acc:73.421303%  |  Open_ACC:74.148605%   |  Close_ACC:72.289162%
2022-08-01 17:28:29,004 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 17:29:49,842 INFO     -------[Epoch]:22-------
2022-08-01 17:29:49,842 INFO     [Train] Loss:0.006564 , Train_Acc:93.230331%
2022-08-01 17:29:49,842 INFO     [Train] Loss_Open:0.000253 , Loss_Close:0.000653%
2022-08-01 17:29:53,064 INFO     [Validate] Val_Acc:73.232796%  |  Open_ACC:74.303406%   |  Close_ACC:71.566269%
2022-08-01 17:29:53,064 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 17:31:17,077 INFO     -------[Epoch]:23-------
2022-08-01 17:31:17,077 INFO     [Train] Loss:0.004587 , Train_Acc:93.596260%
2022-08-01 17:31:17,077 INFO     [Train] Loss_Open:0.000231 , Loss_Close:0.000373%
2022-08-01 17:31:24,753 INFO     [Validate] Val_Acc:72.007538%  |  Open_ACC:72.248062%   |  Close_ACC:71.634621%
2022-08-01 17:31:24,753 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 17:32:52,320 INFO     -------[Epoch]:24-------
2022-08-01 17:32:52,322 INFO     [Train] Loss:0.003775 , Train_Acc:94.267128%
2022-08-01 17:32:52,322 INFO     [Train] Loss_Open:0.000220 , Loss_Close:0.000261%
2022-08-01 17:32:55,521 INFO     [Validate] Val_Acc:73.327049%  |  Open_ACC:74.263565%   |  Close_ACC:71.875000%
2022-08-01 17:32:55,522 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 17:34:17,284 INFO     -------[Epoch]:25-------
2022-08-01 17:34:17,285 INFO     [Train] Loss:0.003700 , Train_Acc:94.490753%
2022-08-01 17:34:17,285 INFO     [Train] Loss_Open:0.000207 , Loss_Close:0.000268%
2022-08-01 17:34:20,585 INFO     [Validate] Val_Acc:72.196037%  |  Open_ACC:73.178291%   |  Close_ACC:70.673080%
2022-08-01 17:34:20,585 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 17:35:50,527 INFO     -------[Epoch]:26-------
2022-08-01 17:35:50,528 INFO     [Train] Loss:0.003576 , Train_Acc:94.694046%
2022-08-01 17:35:50,528 INFO     [Train] Loss_Open:0.000208 , Loss_Close:0.000248%
2022-08-01 17:35:54,278 INFO     [Validate] Val_Acc:74.458061%  |  Open_ACC:74.263565%   |  Close_ACC:74.759621%
2022-08-01 17:35:54,279 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 17:38:09,436 INFO     -------[Epoch]:27-------
2022-08-01 17:38:09,436 INFO     [Train] Loss:0.004608 , Train_Acc:95.120964%
2022-08-01 17:38:09,436 INFO     [Train] Loss_Open:0.000171 , Loss_Close:0.000468%
2022-08-01 17:38:12,463 INFO     [Validate] Val_Acc:73.232796%  |  Open_ACC:73.488373%   |  Close_ACC:72.836540%
2022-08-01 17:38:12,463 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 17:39:49,899 INFO     -------[Epoch]:28-------
2022-08-01 17:39:49,899 INFO     [Train] Loss:0.005255 , Train_Acc:95.690186%
2022-08-01 17:39:49,899 INFO     [Train] Loss_Open:0.000169 , Loss_Close:0.000573%
2022-08-01 17:39:52,997 INFO     [Validate] Val_Acc:72.667297%  |  Open_ACC:72.910217%   |  Close_ACC:72.289162%
2022-08-01 17:39:52,997 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 17:41:23,463 INFO     -------[Epoch]:29-------
2022-08-01 17:41:23,464 INFO     [Train] Loss:0.003953 , Train_Acc:96.076439%
2022-08-01 17:41:23,464 INFO     [Train] Loss_Open:0.000155 , Loss_Close:0.000388%
2022-08-01 17:41:26,607 INFO     [Validate] Val_Acc:72.478790%  |  Open_ACC:73.023254%   |  Close_ACC:71.634621%
2022-08-01 17:41:26,607 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 17:42:59,620 INFO     -------[Epoch]:30-------
2022-08-01 17:42:59,621 INFO     [Train] Loss:0.002909 , Train_Acc:96.361053%
2022-08-01 17:42:59,621 INFO     [Train] Loss_Open:0.000143 , Loss_Close:0.000241%
2022-08-01 17:43:02,756 INFO     [Validate] Val_Acc:73.704056%  |  Open_ACC:73.643410%   |  Close_ACC:73.798080%
2022-08-01 17:43:02,756 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 17:44:23,564 INFO     -------[Epoch]:31-------
2022-08-01 17:44:23,564 INFO     [Train] Loss:0.002287 , Train_Acc:96.137428%
2022-08-01 17:44:23,565 INFO     [Train] Loss_Open:0.000155 , Loss_Close:0.000125%
2022-08-01 17:44:26,567 INFO     [Validate] Val_Acc:72.667297%  |  Open_ACC:73.065010%   |  Close_ACC:72.048195%
2022-08-01 17:44:26,567 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 17:46:25,503 INFO     -------[Epoch]:32-------
2022-08-01 17:46:25,503 INFO     [Train] Loss:0.001498 , Train_Acc:96.991257%
2022-08-01 17:46:25,503 INFO     [Train] Loss_Open:0.000126 , Loss_Close:0.000043%
2022-08-01 17:46:28,844 INFO     [Validate] Val_Acc:72.667297%  |  Open_ACC:73.798447%   |  Close_ACC:70.913467%
2022-08-01 17:46:28,844 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 17:48:21,427 INFO     -------[Epoch]:33-------
2022-08-01 17:48:21,427 INFO     [Train] Loss:0.003154 , Train_Acc:97.153893%
2022-08-01 17:48:21,427 INFO     [Train] Loss_Open:0.000134 , Loss_Close:0.000295%
2022-08-01 17:48:24,735 INFO     [Validate] Val_Acc:73.515549%  |  Open_ACC:74.458199%   |  Close_ACC:72.048195%
2022-08-01 17:48:24,736 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 17:50:47,960 INFO     -------[Epoch]:34-------
2022-08-01 17:50:47,960 INFO     [Train] Loss:0.002497 , Train_Acc:97.560478%
2022-08-01 17:50:47,960 INFO     [Train] Loss_Open:0.000107 , Loss_Close:0.000231%
2022-08-01 17:50:51,177 INFO     [Validate] Val_Acc:74.081055%  |  Open_ACC:75.077400%   |  Close_ACC:72.530121%
2022-08-01 17:50:51,177 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 17:52:43,651 INFO     -------[Epoch]:35-------
2022-08-01 17:52:43,651 INFO     [Train] Loss:0.001908 , Train_Acc:97.662125%
2022-08-01 17:52:43,651 INFO     [Train] Loss_Open:0.000096 , Loss_Close:0.000155%
2022-08-01 17:52:46,596 INFO     [Validate] Val_Acc:73.044296%  |  Open_ACC:74.263565%   |  Close_ACC:71.153847%
2022-08-01 17:52:46,596 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 17:54:32,529 INFO     -------[Epoch]:36-------
2022-08-01 17:54:32,529 INFO     [Train] Loss:0.001382 , Train_Acc:98.190689%
2022-08-01 17:54:32,529 INFO     [Train] Loss_Open:0.000094 , Loss_Close:0.000074%
2022-08-01 17:54:35,584 INFO     [Validate] Val_Acc:73.515549%  |  Open_ACC:73.993805%   |  Close_ACC:72.771088%
2022-08-01 17:54:35,584 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 17:57:00,086 INFO     -------[Epoch]:37-------
2022-08-01 17:57:00,087 INFO     [Train] Loss:0.003632 , Train_Acc:98.373657%
2022-08-01 17:57:00,087 INFO     [Train] Loss_Open:0.000080 , Loss_Close:0.000453%
2022-08-01 17:57:07,753 INFO     [Validate] Val_Acc:73.986801%  |  Open_ACC:75.348839%   |  Close_ACC:71.875000%
2022-08-01 17:57:07,753 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 17:58:28,613 INFO     -------[Epoch]:38-------
2022-08-01 17:58:28,613 INFO     [Train] Loss:0.001472 , Train_Acc:98.556618%
2022-08-01 17:58:28,613 INFO     [Train] Loss_Open:0.000069 , Loss_Close:0.000127%
2022-08-01 17:58:31,646 INFO     [Validate] Val_Acc:72.667297%  |  Open_ACC:73.488373%   |  Close_ACC:71.394234%
2022-08-01 17:58:31,646 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:00:12,224 INFO     -------[Epoch]:39-------
2022-08-01 18:00:12,224 INFO     [Train] Loss:0.001134 , Train_Acc:98.617607%
2022-08-01 18:00:12,224 INFO     [Train] Loss_Open:0.000079 , Loss_Close:0.000058%
2022-08-01 18:00:16,651 INFO     [Validate] Val_Acc:72.573044%  |  Open_ACC:72.600616%   |  Close_ACC:72.530121%
2022-08-01 18:00:16,652 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:02:05,139 INFO     -------[Epoch]:40-------
2022-08-01 18:02:05,139 INFO     [Train] Loss:0.001111 , Train_Acc:98.820900%
2022-08-01 18:02:05,140 INFO     [Train] Loss_Open:0.000062 , Loss_Close:0.000081%
2022-08-01 18:02:08,300 INFO     [Validate] Val_Acc:72.290291%  |  Open_ACC:73.065010%   |  Close_ACC:71.084335%
2022-08-01 18:02:08,300 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:03:29,559 INFO     -------[Epoch]:41-------
2022-08-01 18:03:29,559 INFO     [Train] Loss:0.001038 , Train_Acc:99.207161%
2022-08-01 18:03:29,559 INFO     [Train] Loss_Open:0.000053 , Loss_Close:0.000082%
2022-08-01 18:03:35,828 INFO     [Validate] Val_Acc:72.196037%  |  Open_ACC:73.219810%   |  Close_ACC:70.602409%
2022-08-01 18:03:35,829 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:04:56,836 INFO     -------[Epoch]:42-------
2022-08-01 18:04:56,836 INFO     [Train] Loss:0.003231 , Train_Acc:98.881889%
2022-08-01 18:04:56,836 INFO     [Train] Loss_Open:0.000060 , Loss_Close:0.000420%
2022-08-01 18:04:59,867 INFO     [Validate] Val_Acc:71.724785%  |  Open_ACC:73.488373%   |  Close_ACC:68.990387%
2022-08-01 18:04:59,867 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:06:21,609 INFO     -------[Epoch]:43-------
2022-08-01 18:06:21,609 INFO     [Train] Loss:0.002223 , Train_Acc:99.064850%
2022-08-01 18:06:21,609 INFO     [Train] Loss_Open:0.000059 , Loss_Close:0.000262%
2022-08-01 18:06:24,679 INFO     [Validate] Val_Acc:73.609802%  |  Open_ACC:74.303406%   |  Close_ACC:72.530121%
2022-08-01 18:06:24,679 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:08:16,339 INFO     -------[Epoch]:44-------
2022-08-01 18:08:16,340 INFO     [Train] Loss:0.000851 , Train_Acc:99.288475%
2022-08-01 18:08:16,340 INFO     [Train] Loss_Open:0.000049 , Loss_Close:0.000059%
2022-08-01 18:08:19,390 INFO     [Validate] Val_Acc:72.478790%  |  Open_ACC:72.713181%   |  Close_ACC:72.115387%
2022-08-01 18:08:19,391 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:09:57,624 INFO     -------[Epoch]:45-------
2022-08-01 18:09:57,625 INFO     [Train] Loss:0.000481 , Train_Acc:99.532425%
2022-08-01 18:09:57,625 INFO     [Train] Loss_Open:0.000042 , Loss_Close:0.000012%
2022-08-01 18:10:00,917 INFO     [Validate] Val_Acc:72.950043%  |  Open_ACC:73.643410%   |  Close_ACC:71.875000%
2022-08-01 18:10:00,918 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:11:52,302 INFO     -------[Epoch]:46-------
2022-08-01 18:11:52,303 INFO     [Train] Loss:0.000487 , Train_Acc:99.471436%
2022-08-01 18:11:52,303 INFO     [Train] Loss_Open:0.000050 , Loss_Close:0.000000%
2022-08-01 18:11:55,930 INFO     [Validate] Val_Acc:73.232796%  |  Open_ACC:72.755417%   |  Close_ACC:73.975906%
2022-08-01 18:11:55,931 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:13:40,043 INFO     -------[Epoch]:47-------
2022-08-01 18:13:40,043 INFO     [Train] Loss:0.001189 , Train_Acc:99.268143%
2022-08-01 18:13:40,043 INFO     [Train] Loss_Open:0.000042 , Loss_Close:0.000123%
2022-08-01 18:13:43,169 INFO     [Validate] Val_Acc:73.986801%  |  Open_ACC:74.418602%   |  Close_ACC:73.317314%
2022-08-01 18:13:43,169 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:15:08,945 INFO     -------[Epoch]:48-------
2022-08-01 18:15:08,945 INFO     [Train] Loss:0.001447 , Train_Acc:99.552757%
2022-08-01 18:15:08,945 INFO     [Train] Loss_Open:0.000030 , Loss_Close:0.000182%
2022-08-01 18:15:12,058 INFO     [Validate] Val_Acc:73.232796%  |  Open_ACC:73.953491%   |  Close_ACC:72.115387%
2022-08-01 18:15:12,059 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:16:38,244 INFO     -------[Epoch]:49-------
2022-08-01 18:16:38,244 INFO     [Train] Loss:0.000395 , Train_Acc:99.573082%
2022-08-01 18:16:38,244 INFO     [Train] Loss_Open:0.000039 , Loss_Close:0.000003%
2022-08-01 18:16:46,411 INFO     [Validate] Val_Acc:72.950043%  |  Open_ACC:73.684212%   |  Close_ACC:71.807228%
2022-08-01 18:16:46,412 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:18:10,754 INFO     -------[Epoch]:50-------
2022-08-01 18:18:10,754 INFO     [Train] Loss:0.005250 , Train_Acc:99.654404%
2022-08-01 18:18:10,754 INFO     [Train] Loss_Open:0.000032 , Loss_Close:0.000782%
2022-08-01 18:18:17,447 INFO     [Validate] Val_Acc:73.421303%  |  Open_ACC:73.488373%   |  Close_ACC:73.317314%
2022-08-01 18:18:17,448 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:20:06,174 INFO     -------[Epoch]:51-------
2022-08-01 18:20:06,175 INFO     [Train] Loss:0.001808 , Train_Acc:99.390121%
2022-08-01 18:20:06,175 INFO     [Train] Loss_Open:0.000035 , Loss_Close:0.000232%
2022-08-01 18:20:15,386 INFO     [Validate] Val_Acc:73.232796%  |  Open_ACC:73.798447%   |  Close_ACC:72.355774%
2022-08-01 18:20:15,386 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:22:51,853 INFO     -------[Epoch]:52-------
2022-08-01 18:22:51,853 INFO     [Train] Loss:0.000958 , Train_Acc:99.573082%
2022-08-01 18:22:51,854 INFO     [Train] Loss_Open:0.000042 , Loss_Close:0.000087%
2022-08-01 18:22:55,004 INFO     [Validate] Val_Acc:72.855797%  |  Open_ACC:73.178291%   |  Close_ACC:72.355774%
2022-08-01 18:22:55,004 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:24:47,045 INFO     -------[Epoch]:53-------
2022-08-01 18:24:47,045 INFO     [Train] Loss:0.000233 , Train_Acc:99.735718%
2022-08-01 18:24:47,045 INFO     [Train] Loss_Open:0.000024 , Loss_Close:0.000000%
2022-08-01 18:24:50,258 INFO     [Validate] Val_Acc:73.609802%  |  Open_ACC:75.232193%   |  Close_ACC:71.084335%
2022-08-01 18:24:50,259 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:26:11,744 INFO     -------[Epoch]:54-------
2022-08-01 18:26:11,744 INFO     [Train] Loss:0.001051 , Train_Acc:99.491768%
2022-08-01 18:26:11,744 INFO     [Train] Loss_Open:0.000051 , Loss_Close:0.000087%
2022-08-01 18:26:15,032 INFO     [Validate] Val_Acc:74.175308%  |  Open_ACC:76.160988%   |  Close_ACC:71.084335%
2022-08-01 18:26:15,032 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:28:57,988 INFO     -------[Epoch]:55-------
2022-08-01 18:28:57,988 INFO     [Train] Loss:0.001274 , Train_Acc:99.573082%
2022-08-01 18:28:57,988 INFO     [Train] Loss_Open:0.000028 , Loss_Close:0.000158%
2022-08-01 18:29:00,993 INFO     [Validate] Val_Acc:73.704056%  |  Open_ACC:73.839005%   |  Close_ACC:73.493980%
2022-08-01 18:29:00,994 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:31:13,133 INFO     -------[Epoch]:56-------
2022-08-01 18:31:13,134 INFO     [Train] Loss:0.000349 , Train_Acc:99.857697%
2022-08-01 18:31:13,134 INFO     [Train] Loss_Open:0.000019 , Loss_Close:0.000026%
2022-08-01 18:31:16,276 INFO     [Validate] Val_Acc:73.892555%  |  Open_ACC:73.993805%   |  Close_ACC:73.734940%
2022-08-01 18:31:16,277 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:33:38,776 INFO     -------[Epoch]:57-------
2022-08-01 18:33:38,776 INFO     [Train] Loss:0.000710 , Train_Acc:99.695061%
2022-08-01 18:33:38,776 INFO     [Train] Loss_Open:0.000021 , Loss_Close:0.000080%
2022-08-01 18:33:42,079 INFO     [Validate] Val_Acc:73.138550%  |  Open_ACC:74.148605%   |  Close_ACC:71.566269%
2022-08-01 18:33:42,081 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:35:36,665 INFO     -------[Epoch]:58-------
2022-08-01 18:35:36,665 INFO     [Train] Loss:0.002025 , Train_Acc:99.593414%
2022-08-01 18:35:36,665 INFO     [Train] Loss_Open:0.000021 , Loss_Close:0.000288%
2022-08-01 18:35:42,132 INFO     [Validate] Val_Acc:73.609802%  |  Open_ACC:73.643410%   |  Close_ACC:73.557693%
2022-08-01 18:35:42,132 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:37:03,203 INFO     -------[Epoch]:59-------
2022-08-01 18:37:03,204 INFO     [Train] Loss:0.000476 , Train_Acc:99.756050%
2022-08-01 18:37:03,204 INFO     [Train] Loss_Open:0.000025 , Loss_Close:0.000036%
2022-08-01 18:37:06,260 INFO     [Validate] Val_Acc:72.573044%  |  Open_ACC:73.488373%   |  Close_ACC:71.153847%
2022-08-01 18:37:06,260 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:39:47,005 INFO     -------[Epoch]:60-------
2022-08-01 18:39:47,005 INFO     [Train] Loss:0.002080 , Train_Acc:99.674728%
2022-08-01 18:39:47,005 INFO     [Train] Loss_Open:0.000012 , Loss_Close:0.000311%
2022-08-01 18:39:50,109 INFO     [Validate] Val_Acc:72.667297%  |  Open_ACC:73.065010%   |  Close_ACC:72.048195%
2022-08-01 18:39:50,109 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:41:14,501 INFO     -------[Epoch]:61-------
2022-08-01 18:41:14,502 INFO     [Train] Loss:0.000624 , Train_Acc:99.796707%
2022-08-01 18:41:14,502 INFO     [Train] Loss_Open:0.000026 , Loss_Close:0.000058%
2022-08-01 18:41:23,521 INFO     [Validate] Val_Acc:70.970779%  |  Open_ACC:70.897827%   |  Close_ACC:71.084335%
2022-08-01 18:41:23,521 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:43:44,281 INFO     -------[Epoch]:62-------
2022-08-01 18:43:44,281 INFO     [Train] Loss:0.000375 , Train_Acc:99.837364%
2022-08-01 18:43:44,281 INFO     [Train] Loss_Open:0.000029 , Loss_Close:0.000015%
2022-08-01 18:43:47,518 INFO     [Validate] Val_Acc:72.950043%  |  Open_ACC:73.488373%   |  Close_ACC:72.115387%
2022-08-01 18:43:47,518 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:46:20,011 INFO     -------[Epoch]:63-------
2022-08-01 18:46:20,011 INFO     [Train] Loss:0.000383 , Train_Acc:99.796707%
2022-08-01 18:46:20,011 INFO     [Train] Loss_Open:0.000021 , Loss_Close:0.000027%
2022-08-01 18:46:28,404 INFO     [Validate] Val_Acc:72.573044%  |  Open_ACC:73.953491%   |  Close_ACC:70.432693%
2022-08-01 18:46:28,404 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:48:07,965 INFO     -------[Epoch]:64-------
2022-08-01 18:48:07,965 INFO     [Train] Loss:0.000522 , Train_Acc:99.878029%
2022-08-01 18:48:07,965 INFO     [Train] Loss_Open:0.000025 , Loss_Close:0.000045%
2022-08-01 18:48:11,049 INFO     [Validate] Val_Acc:71.913292%  |  Open_ACC:73.065010%   |  Close_ACC:70.120483%
2022-08-01 18:48:11,050 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:49:35,003 INFO     -------[Epoch]:65-------
2022-08-01 18:49:35,003 INFO     [Train] Loss:0.001103 , Train_Acc:99.796707%
2022-08-01 18:49:35,003 INFO     [Train] Loss_Open:0.000012 , Loss_Close:0.000156%
2022-08-01 18:49:38,076 INFO     [Validate] Val_Acc:71.347786%  |  Open_ACC:72.248062%   |  Close_ACC:69.951927%
2022-08-01 18:49:38,077 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:51:37,595 INFO     -------[Epoch]:66-------
2022-08-01 18:51:37,595 INFO     [Train] Loss:0.000451 , Train_Acc:99.817039%
2022-08-01 18:51:37,595 INFO     [Train] Loss_Open:0.000022 , Loss_Close:0.000037%
2022-08-01 18:51:40,675 INFO     [Validate] Val_Acc:71.724785%  |  Open_ACC:72.445816%   |  Close_ACC:70.602409%
2022-08-01 18:51:40,675 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:53:13,701 INFO     -------[Epoch]:67-------
2022-08-01 18:53:13,701 INFO     [Train] Loss:0.000143 , Train_Acc:99.898354%
2022-08-01 18:53:13,701 INFO     [Train] Loss_Open:0.000006 , Loss_Close:0.000013%
2022-08-01 18:53:17,049 INFO     [Validate] Val_Acc:72.667297%  |  Open_ACC:73.529411%   |  Close_ACC:71.325302%
2022-08-01 18:53:17,049 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 18:54:38,882 INFO     -------[Epoch]:68-------
2022-08-01 18:54:38,882 INFO     [Train] Loss:0.001421 , Train_Acc:99.837364%
2022-08-01 18:54:38,882 INFO     [Train] Loss_Open:0.000015 , Loss_Close:0.000202%
2022-08-01 18:54:41,885 INFO     [Validate] Val_Acc:73.138550%  |  Open_ACC:74.263565%   |  Close_ACC:71.394234%
2022-08-01 18:54:41,885 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:56:54,747 INFO     -------[Epoch]:69-------
2022-08-01 18:56:54,747 INFO     [Train] Loss:0.000836 , Train_Acc:99.878029%
2022-08-01 18:56:54,747 INFO     [Train] Loss_Open:0.000014 , Loss_Close:0.000111%
2022-08-01 18:56:57,723 INFO     [Validate] Val_Acc:73.421303%  |  Open_ACC:74.418602%   |  Close_ACC:71.875000%
2022-08-01 18:56:57,723 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 18:58:19,060 INFO     -------[Epoch]:70-------
2022-08-01 18:58:19,061 INFO     [Train] Loss:0.002143 , Train_Acc:99.715393%
2022-08-01 18:58:19,061 INFO     [Train] Loss_Open:0.000013 , Loss_Close:0.000319%
2022-08-01 18:58:22,175 INFO     [Validate] Val_Acc:72.290291%  |  Open_ACC:73.488373%   |  Close_ACC:70.432693%
2022-08-01 18:58:22,175 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:00:23,698 INFO     -------[Epoch]:71-------
2022-08-01 19:00:23,698 INFO     [Train] Loss:0.000663 , Train_Acc:99.817039%
2022-08-01 19:00:23,698 INFO     [Train] Loss_Open:0.000011 , Loss_Close:0.000088%
2022-08-01 19:00:31,813 INFO     [Validate] Val_Acc:73.515549%  |  Open_ACC:74.612999%   |  Close_ACC:71.807228%
2022-08-01 19:00:31,813 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 19:02:48,354 INFO     -------[Epoch]:72-------
2022-08-01 19:02:48,354 INFO     [Train] Loss:0.000773 , Train_Acc:99.796707%
2022-08-01 19:02:48,354 INFO     [Train] Loss_Open:0.000024 , Loss_Close:0.000085%
2022-08-01 19:02:51,447 INFO     [Validate] Val_Acc:72.007538%  |  Open_ACC:72.755417%   |  Close_ACC:70.843376%
2022-08-01 19:02:51,447 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 19:04:13,068 INFO     -------[Epoch]:73-------
2022-08-01 19:04:13,068 INFO     [Train] Loss:0.000047 , Train_Acc:99.959343%
2022-08-01 19:04:13,068 INFO     [Train] Loss_Open:0.000005 , Loss_Close:0.000000%
2022-08-01 19:04:17,847 INFO     [Validate] Val_Acc:72.290291%  |  Open_ACC:73.178291%   |  Close_ACC:70.913467%
2022-08-01 19:04:17,848 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:05:55,304 INFO     -------[Epoch]:74-------
2022-08-01 19:05:55,304 INFO     [Train] Loss:0.002252 , Train_Acc:99.837364%
2022-08-01 19:05:55,304 INFO     [Train] Loss_Open:0.000023 , Loss_Close:0.000322%
2022-08-01 19:05:58,318 INFO     [Validate] Val_Acc:71.065033%  |  Open_ACC:72.093025%   |  Close_ACC:69.471153%
2022-08-01 19:05:58,318 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:07:19,681 INFO     -------[Epoch]:75-------
2022-08-01 19:07:19,681 INFO     [Train] Loss:0.000776 , Train_Acc:99.817039%
2022-08-01 19:07:19,681 INFO     [Train] Loss_Open:0.000014 , Loss_Close:0.000101%
2022-08-01 19:07:22,934 INFO     [Validate] Val_Acc:72.290291%  |  Open_ACC:72.445816%   |  Close_ACC:72.048195%
2022-08-01 19:07:22,934 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 19:10:31,678 INFO     -------[Epoch]:76-------
2022-08-01 19:10:31,679 INFO     [Train] Loss:0.000402 , Train_Acc:99.959343%
2022-08-01 19:10:31,679 INFO     [Train] Loss_Open:0.000005 , Loss_Close:0.000056%
2022-08-01 19:10:39,332 INFO     [Validate] Val_Acc:72.761543%  |  Open_ACC:73.684212%   |  Close_ACC:71.325302%
2022-08-01 19:10:39,333 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 19:12:33,208 INFO     -------[Epoch]:77-------
2022-08-01 19:12:33,208 INFO     [Train] Loss:0.001995 , Train_Acc:99.898354%
2022-08-01 19:12:33,208 INFO     [Train] Loss_Open:0.000006 , Loss_Close:0.000306%
2022-08-01 19:12:36,201 INFO     [Validate] Val_Acc:71.913292%  |  Open_ACC:72.248062%   |  Close_ACC:71.394234%
2022-08-01 19:12:36,201 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:15:40,241 INFO     -------[Epoch]:78-------
2022-08-01 19:15:40,241 INFO     [Train] Loss:0.000633 , Train_Acc:99.878029%
2022-08-01 19:15:40,241 INFO     [Train] Loss_Open:0.000011 , Loss_Close:0.000082%
2022-08-01 19:15:43,251 INFO     [Validate] Val_Acc:72.478790%  |  Open_ACC:73.488373%   |  Close_ACC:70.913467%
2022-08-01 19:15:43,251 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:17:04,373 INFO     -------[Epoch]:79-------
2022-08-01 19:17:04,373 INFO     [Train] Loss:0.000642 , Train_Acc:99.837364%
2022-08-01 19:17:04,373 INFO     [Train] Loss_Open:0.000019 , Loss_Close:0.000072%
2022-08-01 19:17:07,334 INFO     [Validate] Val_Acc:72.855797%  |  Open_ACC:73.178291%   |  Close_ACC:72.355774%
2022-08-01 19:17:07,335 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:19:00,366 INFO     -------[Epoch]:80-------
2022-08-01 19:19:00,366 INFO     [Train] Loss:0.000201 , Train_Acc:99.898354%
2022-08-01 19:19:00,366 INFO     [Train] Loss_Open:0.000020 , Loss_Close:0.000000%
2022-08-01 19:19:03,395 INFO     [Validate] Val_Acc:72.667297%  |  Open_ACC:72.713181%   |  Close_ACC:72.596153%
2022-08-01 19:19:03,395 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:20:30,563 INFO     -------[Epoch]:81-------
2022-08-01 19:20:30,563 INFO     [Train] Loss:0.000049 , Train_Acc:99.979675%
2022-08-01 19:20:30,563 INFO     [Train] Loss_Open:0.000005 , Loss_Close:0.000000%
2022-08-01 19:20:33,609 INFO     [Validate] Val_Acc:73.138550%  |  Open_ACC:73.488373%   |  Close_ACC:72.596153%
2022-08-01 19:20:33,610 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:22:57,042 INFO     -------[Epoch]:82-------
2022-08-01 19:22:57,042 INFO     [Train] Loss:0.000123 , Train_Acc:99.939011%
2022-08-01 19:22:57,042 INFO     [Train] Loss_Open:0.000008 , Loss_Close:0.000007%
2022-08-01 19:22:59,971 INFO     [Validate] Val_Acc:72.290291%  |  Open_ACC:71.937981%   |  Close_ACC:72.836540%
2022-08-01 19:22:59,971 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:24:36,156 INFO     -------[Epoch]:83-------
2022-08-01 19:24:36,156 INFO     [Train] Loss:0.000830 , Train_Acc:99.735718%
2022-08-01 19:24:36,156 INFO     [Train] Loss_Open:0.000019 , Loss_Close:0.000103%
2022-08-01 19:24:39,514 INFO     [Validate] Val_Acc:71.630539%  |  Open_ACC:71.162788%   |  Close_ACC:72.355774%
2022-08-01 19:24:39,514 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:26:00,547 INFO     -------[Epoch]:84-------
2022-08-01 19:26:00,547 INFO     [Train] Loss:0.001087 , Train_Acc:99.756050%
2022-08-01 19:26:00,547 INFO     [Train] Loss_Open:0.000011 , Loss_Close:0.000155%
2022-08-01 19:26:03,560 INFO     [Validate] Val_Acc:72.290291%  |  Open_ACC:72.558136%   |  Close_ACC:71.875000%
2022-08-01 19:26:03,560 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:27:24,766 INFO     -------[Epoch]:85-------
2022-08-01 19:27:24,766 INFO     [Train] Loss:0.000098 , Train_Acc:99.939011%
2022-08-01 19:27:24,766 INFO     [Train] Loss_Open:0.000010 , Loss_Close:0.000000%
2022-08-01 19:27:28,015 INFO     [Validate] Val_Acc:72.101791%  |  Open_ACC:71.472870%   |  Close_ACC:73.076927%
2022-08-01 19:27:28,015 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:28:49,669 INFO     -------[Epoch]:86-------
2022-08-01 19:28:49,669 INFO     [Train] Loss:0.000045 , Train_Acc:99.979675%
2022-08-01 19:28:49,669 INFO     [Train] Loss_Open:0.000004 , Loss_Close:0.000000%
2022-08-01 19:28:52,665 INFO     [Validate] Val_Acc:73.044296%  |  Open_ACC:72.713181%   |  Close_ACC:73.557693%
2022-08-01 19:28:52,666 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:30:13,917 INFO     -------[Epoch]:87-------
2022-08-01 19:30:13,917 INFO     [Train] Loss:0.000174 , Train_Acc:99.776382%
2022-08-01 19:30:13,917 INFO     [Train] Loss_Open:0.000017 , Loss_Close:0.000000%
2022-08-01 19:30:17,182 INFO     [Validate] Val_Acc:72.573044%  |  Open_ACC:71.981422%   |  Close_ACC:73.493980%
2022-08-01 19:30:17,182 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 19:31:42,084 INFO     -------[Epoch]:88-------
2022-08-01 19:31:42,084 INFO     [Train] Loss:0.000127 , Train_Acc:99.878029%
2022-08-01 19:31:42,085 INFO     [Train] Loss_Open:0.000013 , Loss_Close:0.000000%
2022-08-01 19:31:45,231 INFO     [Validate] Val_Acc:73.327049%  |  Open_ACC:73.333336%   |  Close_ACC:73.317314%
2022-08-01 19:31:45,231 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:33:57,097 INFO     -------[Epoch]:89-------
2022-08-01 19:33:57,097 INFO     [Train] Loss:0.000149 , Train_Acc:99.939011%
2022-08-01 19:33:57,097 INFO     [Train] Loss_Open:0.000007 , Loss_Close:0.000012%
2022-08-01 19:34:02,712 INFO     [Validate] Val_Acc:73.232796%  |  Open_ACC:73.798447%   |  Close_ACC:72.355774%
2022-08-01 19:34:02,713 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:35:31,592 INFO     -------[Epoch]:90-------
2022-08-01 19:35:31,592 INFO     [Train] Loss:0.001326 , Train_Acc:99.756050%
2022-08-01 19:35:31,592 INFO     [Train] Loss_Open:0.000020 , Loss_Close:0.000179%
2022-08-01 19:35:34,746 INFO     [Validate] Val_Acc:73.138550%  |  Open_ACC:72.910217%   |  Close_ACC:73.493980%
2022-08-01 19:35:34,746 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 19:37:30,373 INFO     -------[Epoch]:91-------
2022-08-01 19:37:30,373 INFO     [Train] Loss:0.000043 , Train_Acc:99.979675%
2022-08-01 19:37:30,373 INFO     [Train] Loss_Open:0.000003 , Loss_Close:0.000001%
2022-08-01 19:37:33,674 INFO     [Validate] Val_Acc:73.138550%  |  Open_ACC:72.868217%   |  Close_ACC:73.557693%
2022-08-01 19:37:33,675 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:39:46,930 INFO     -------[Epoch]:92-------
2022-08-01 19:39:46,930 INFO     [Train] Loss:0.000478 , Train_Acc:99.878029%
2022-08-01 19:39:46,931 INFO     [Train] Loss_Open:0.000013 , Loss_Close:0.000055%
2022-08-01 19:39:50,336 INFO     [Validate] Val_Acc:73.892555%  |  Open_ACC:74.263565%   |  Close_ACC:73.317314%
2022-08-01 19:39:50,337 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:41:13,476 INFO     -------[Epoch]:93-------
2022-08-01 19:41:13,476 INFO     [Train] Loss:0.000241 , Train_Acc:99.817039%
2022-08-01 19:41:13,476 INFO     [Train] Loss_Open:0.000022 , Loss_Close:0.000003%
2022-08-01 19:41:16,477 INFO     [Validate] Val_Acc:73.327049%  |  Open_ACC:73.684212%   |  Close_ACC:72.771088%
2022-08-01 19:41:16,477 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 19:43:07,959 INFO     -------[Epoch]:94-------
2022-08-01 19:43:07,959 INFO     [Train] Loss:0.000416 , Train_Acc:99.817039%
2022-08-01 19:43:07,959 INFO     [Train] Loss_Open:0.000013 , Loss_Close:0.000045%
2022-08-01 19:43:11,136 INFO     [Validate] Val_Acc:72.761543%  |  Open_ACC:73.798447%   |  Close_ACC:71.153847%
2022-08-01 19:43:11,137 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:44:55,652 INFO     -------[Epoch]:95-------
2022-08-01 19:44:55,652 INFO     [Train] Loss:0.001793 , Train_Acc:99.918686%
2022-08-01 19:44:55,652 INFO     [Train] Loss_Open:0.000011 , Loss_Close:0.000267%
2022-08-01 19:45:02,256 INFO     [Validate] Val_Acc:72.478790%  |  Open_ACC:73.023254%   |  Close_ACC:71.634621%
2022-08-01 19:45:02,257 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:46:23,566 INFO     -------[Epoch]:96-------
2022-08-01 19:46:23,567 INFO     [Train] Loss:0.000240 , Train_Acc:99.918686%
2022-08-01 19:46:23,567 INFO     [Train] Loss_Open:0.000003 , Loss_Close:0.000033%
2022-08-01 19:46:26,736 INFO     [Validate] Val_Acc:72.573044%  |  Open_ACC:73.333336%   |  Close_ACC:71.394234%
2022-08-01 19:46:26,737 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:48:04,446 INFO     -------[Epoch]:97-------
2022-08-01 19:48:04,446 INFO     [Train] Loss:0.000046 , Train_Acc:99.979675%
2022-08-01 19:48:04,446 INFO     [Train] Loss_Open:0.000004 , Loss_Close:0.000000%
2022-08-01 19:48:07,454 INFO     [Validate] Val_Acc:72.950043%  |  Open_ACC:73.798447%   |  Close_ACC:71.634621%
2022-08-01 19:48:07,454 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:49:41,725 INFO     -------[Epoch]:98-------
2022-08-01 19:49:41,725 INFO     [Train] Loss:0.001509 , Train_Acc:99.878029%
2022-08-01 19:49:41,726 INFO     [Train] Loss_Open:0.000007 , Loss_Close:0.000228%
2022-08-01 19:49:45,047 INFO     [Validate] Val_Acc:73.421303%  |  Open_ACC:75.232193%   |  Close_ACC:70.602409%
2022-08-01 19:49:45,047 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 19:51:06,624 INFO     -------[Epoch]:99-------
2022-08-01 19:51:06,624 INFO     [Train] Loss:0.000744 , Train_Acc:99.857697%
2022-08-01 19:51:06,624 INFO     [Train] Loss_Open:0.000005 , Loss_Close:0.000110%
2022-08-01 19:51:09,639 INFO     [Validate] Val_Acc:72.384544%  |  Open_ACC:73.684212%   |  Close_ACC:70.361450%
2022-08-01 19:51:09,639 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 19:52:36,657 INFO     -------[Epoch]:100-------
2022-08-01 19:52:36,657 INFO     [Train] Loss:0.000297 , Train_Acc:99.878029%
2022-08-01 19:52:36,657 INFO     [Train] Loss_Open:0.000011 , Loss_Close:0.000030%
2022-08-01 19:52:39,882 INFO     [Validate] Val_Acc:73.515549%  |  Open_ACC:73.993805%   |  Close_ACC:72.771088%
2022-08-01 19:52:39,882 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 19:54:01,129 INFO     -------[Epoch]:101-------
2022-08-01 19:54:01,129 INFO     [Train] Loss:0.000415 , Train_Acc:99.959343%
2022-08-01 19:54:01,130 INFO     [Train] Loss_Open:0.000009 , Loss_Close:0.000052%
2022-08-01 19:54:04,370 INFO     [Validate] Val_Acc:73.892555%  |  Open_ACC:74.263565%   |  Close_ACC:73.317314%
2022-08-01 19:54:04,370 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:55:27,181 INFO     -------[Epoch]:102-------
2022-08-01 19:55:27,181 INFO     [Train] Loss:0.000991 , Train_Acc:99.939011%
2022-08-01 19:55:27,181 INFO     [Train] Loss_Open:0.000002 , Loss_Close:0.000154%
2022-08-01 19:55:30,270 INFO     [Validate] Val_Acc:72.950043%  |  Open_ACC:72.755417%   |  Close_ACC:73.253014%
2022-08-01 19:55:30,270 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
2022-08-01 19:57:23,465 INFO     -------[Epoch]:103-------
2022-08-01 19:57:23,465 INFO     [Train] Loss:0.000634 , Train_Acc:99.918686%
2022-08-01 19:57:23,465 INFO     [Train] Loss_Open:0.000004 , Loss_Close:0.000094%
2022-08-01 19:57:26,431 INFO     [Validate] Val_Acc:72.290291%  |  Open_ACC:72.248062%   |  Close_ACC:72.355774%
2022-08-01 19:57:26,431 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 645.0 416.0
2022-08-01 19:59:50,588 INFO     -------[Epoch]:104-------
2022-08-01 19:59:50,588 INFO     [Train] Loss:0.000445 , Train_Acc:99.878029%
2022-08-01 19:59:50,588 INFO     [Train] Loss_Open:0.000007 , Loss_Close:0.000060%
2022-08-01 19:59:53,636 INFO     [Validate] Val_Acc:72.855797%  |  Open_ACC:73.219810%   |  Close_ACC:72.289162%
2022-08-01 19:59:53,637 INFO     [Result] The best acc is 74.646561% at epoch 19
1061 646.0 415.0
